"""
Tests autonomes des amÃ©liorations SophIA
Version complÃ¨te sans dÃ©pendances externes
"""

import sys
import os

# Configuration des imports
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, ROOT_DIR)

# Utilitaires de test intÃ©grÃ©s (pas d'import externe)
def assert_valid_response(response, min_length=10):
    """VÃ©rifie qu'une rÃ©ponse SophIA est valide"""
    assert response is not None
    assert hasattr(response, 'natural_response')
    assert hasattr(response, 'conceptual_analysis')
    assert len(response.natural_response) >= min_length
    assert 'concepts_detected' in response.conceptual_analysis

def assert_concepts_detected(response, expected_concepts, min_match=1):
    """VÃ©rifie que les concepts attendus sont dÃ©tectÃ©s"""
    detected = response.conceptual_analysis.get('concepts_detected', [])
    matches = sum(1 for concept in expected_concepts if concept in detected)
    assert matches >= min_match, f"Expected at least {min_match} concepts from {expected_concepts}, got {detected}"

def measure_response_time(func, *args, **kwargs):
    """Mesure le temps de rÃ©ponse d'une fonction"""
    import time
    start = time.time()
    result = func(*args, **kwargs)
    end = time.time()
    return result, end - start

def test_concept_bridge():
    """Teste le pont conceptuel amÃ©liorÃ©"""
    print("ğŸ”— Test du Concept Bridge...")
    
    try:
        from sophia.bridge.concept_text_bridge import EnhancedConceptTextBridge
        from sophia.core.ontology import SimpleOntology
        from sophia.llm.llama_interface import OllamaLLaMAInterface
        
        ontology = SimpleOntology()
        llm = OllamaLLaMAInterface()
        bridge = EnhancedConceptTextBridge(ontology, llm)
        
        # Test d'initialisation
        assert bridge.ontology is not None
        assert bridge.llm is not None
        assert len(bridge.concept_patterns) > 0
        print("  âœ… Initialisation rÃ©ussie")
        
        # Test des synonymes amÃ©liorÃ©s
        print("  ğŸ” Test gÃ©nÃ©ration synonymes...")
        synonyms = bridge._get_concept_synonyms('VÃ‰RITÃ‰')
        assert isinstance(synonyms, list)
        assert len(synonyms) > 0
        print(f"  âœ… Synonymes pour VÃ‰RITÃ‰: {synonyms[:5]}...")
        
        # Test de l'extraction amÃ©liorÃ©e
        print("  ğŸ” Test extraction amÃ©liorÃ©e...")
        test_text = "La vÃ©ritÃ© philosophique est-elle relative Ã  notre perception de la justice ?"
        base_extraction = {'concepts_detected': ['VÃ‰RITÃ‰'], 'confidence': 0.8}
        
        enhanced = bridge.enhanced_concept_extraction(test_text, base_extraction)
        
        assert 'enhanced_confidence' in enhanced
        assert 'concept_matches' in enhanced
        assert 'concepts_detailed' in enhanced
        assert 0.0 <= enhanced['enhanced_confidence'] <= 1.0
        
        print(f"  âœ… Concepts dÃ©tectÃ©s: {enhanced['concepts_detected']}")
        print(f"  âœ… Confiance amÃ©liorÃ©e: {enhanced['enhanced_confidence']:.2f}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Erreur Bridge: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_constraint_manager():
    """Teste le gestionnaire de contraintes"""
    print("\nâš–ï¸ Test du Constraint Manager...")
    
    try:
        from sophia.constraints.constraint_manager import PhilosophicalConstraintManager
        from sophia.core.ontology import SimpleOntology
        from sophia.llm.llama_interface import OllamaLLaMAInterface
        
        ontology = SimpleOntology()
        llm = OllamaLLaMAInterface()
        constraint_manager = PhilosophicalConstraintManager(ontology, llm)
        
        # Test d'initialisation
        assert constraint_manager.ontology is not None
        assert constraint_manager.llm is not None
        assert len(constraint_manager.constraints) > 0
        assert len(constraint_manager.philosophical_clusters) > 0
        print("  âœ… Initialisation rÃ©ussie")
        
        # Test des clusters philosophiques
        clusters = constraint_manager.philosophical_clusters
        cluster_names = [c['name'] for c in clusters]
        
        expected_clusters = ['Ã‰pistÃ©mologie', 'Ã‰thique', 'MÃ©taphysique']
        found_clusters = [name for name in expected_clusters if name in cluster_names]
        
        print(f"  âœ… Clusters trouvÃ©s: {found_clusters}")
        print(f"  âœ… Total clusters: {len(clusters)}")
        
        # Test de validation
        print("  ğŸ” Test validation rÃ©ponse...")
        test_response = """La vÃ©ritÃ© est un concept philosophique fondamental. 
        Tout d'abord, elle peut Ãªtre considÃ©rÃ©e comme absolue selon Platon. 
        Ensuite, elle peut Ãªtre relative selon les sophistes. 
        Enfin, elle dÃ©pend de notre capacitÃ© Ã  connaÃ®tre la rÃ©alitÃ©."""
        
        test_context = {
            'concepts_detected': ['VÃ‰RITÃ‰', 'CONNAISSANCE'],
            'question': 'Qu\'est-ce que la vÃ©ritÃ© ?'
        }
        
        validation = constraint_manager.validate_response(test_response, test_context)
        
        assert 'global_score' in validation
        assert 'constraint_results' in validation
        assert 'is_valid' in validation
        assert 0.0 <= validation['global_score'] <= 1.0
        
        print(f"  âœ… Score global: {validation['global_score']:.2f}")
        print(f"  âœ… Contraintes actives: {len(constraint_manager.constraints)}")
        print(f"  âœ… Validation rÃ©ussie: {validation['is_valid']}")
        
        if validation.get('recommendations'):
            print(f"  ğŸ’¡ Recommandations: {len(validation['recommendations'])}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Erreur Constraints: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_enhanced_sophia():
    """Teste SophIA avec les amÃ©liorations"""
    print("\nğŸ§  Test de SophIA Enhanced...")
    
    try:
        from sophia.core.sophia_hybrid import HybridSophIA
        
        print("  ğŸš€ Initialisation...")
        sophia = HybridSophIA(session_name="test_enhanced", auto_save=False)
        
        # VÃ©rifications d'initialisation
        assert hasattr(sophia, 'concept_bridge')
        assert hasattr(sophia, 'constraint_manager')
        assert sophia.concept_bridge is not None
        assert sophia.constraint_manager is not None
        
        print("  âœ… SophIA Enhanced initialisÃ©e !")
        print(f"  ğŸ“š Ontologie: {len(sophia.ontology.concepts)} concepts")
        print(f"  ğŸ”— Bridge actif: True")
        print(f"  âš–ï¸ Constraint manager actif: True")
        
        # Test de conversation
        print("\n  ğŸ’¬ Test de conversation...")
        questions = [
            "Qu'est-ce que la vÃ©ritÃ© ?",
            "La justice peut-elle Ãªtre absolue ?"
        ]
        
        for i, question in enumerate(questions, 1):
            print(f"\n  ğŸ“ Question {i}: {question}")
            
            response = sophia.ask(question)
            
            # VÃ©rifications de base
            assert_valid_response(response, min_length=30)
            assert hasattr(response, 'validation_report')
            assert response.confidence > 0.0
            
            print(f"    ğŸ§  RÃ©ponse: {response.natural_response[:100]}...")
            
            concepts = response.conceptual_analysis.get('concepts_detected', [])
            print(f"    ğŸ’¡ Concepts: {concepts}")
            print(f"    ğŸ¯ Confiance: {response.confidence:.2f}")
            
            if 'global_score' in response.validation_report:
                print(f"    ğŸ“Š Score validation: {response.validation_report['global_score']:.2f}")
        
        # Test du raisonnement dÃ©taillÃ©
        print("\n  ğŸ” Test d'explication du raisonnement:")
        explanation = sophia.explain_reasoning("Qu'est-ce que la justice ?")
        
        required_steps = ['step1_concept_detection', 'step2_conceptual_reasoning', 
                         'step3_constraint_validation', 'step4_synthesis']
        
        for step in required_steps:
            assert step in explanation, f"Ã‰tape manquante: {step}"
        
        print(f"    âœ… Toutes les Ã©tapes prÃ©sentes: {len(required_steps)}")
        print(f"    - MÃ©thode: {explanation['step1_concept_detection']['method']}")
        
        if 'concepts_found' in explanation['step1_concept_detection']:
            concepts_found = explanation['step1_concept_detection']['concepts_found']
            print(f"    - Concepts trouvÃ©s: {concepts_found}")
        
        # Test du rÃ©sumÃ© amÃ©liorÃ©
        print("\n  ğŸ“Š Test du rÃ©sumÃ© de conversation:")
        summary = sophia.get_conversation_summary()
        
        assert 'total_interactions' in summary
        assert 'average_confidence' in summary
        
        print(f"    - Interactions: {summary['total_interactions']}")
        print(f"    - Confiance moyenne: {summary['average_confidence']:.2f}")
        
        if 'system_performance' in summary:
            perf = summary['system_performance']
            print(f"    - Bridge actif: {perf.get('concept_bridge_active', 'N/A')}")
            print(f"    - Constraints actifs: {perf.get('constraint_manager_active', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Erreur SophIA Enhanced: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance():
    """Teste les performances"""
    print("\nâš¡ Test de Performance...")
    
    try:
        from sophia.core.sophia_hybrid import HybridSophIA
        
        sophia = HybridSophIA(session_name="test_perf", auto_save=False)
        
        question = "Qu'est-ce que la vÃ©ritÃ© ?"
        print(f"  ğŸ” Test avec question: {question}")
        
        response, duration = measure_response_time(sophia.ask, question)
        
        assert_valid_response(response)
        print(f"  âœ… Temps de rÃ©ponse: {duration:.2f}s")
        
        # Ã‰valuation performance
        if duration < 10.0:
            print(f"  ğŸš€ Performance excellente (< 10s)")
        elif duration < 30.0:
            print(f"  âœ… Performance acceptable (< 30s)")
        else:
            print(f"  âš ï¸ Performance lente (> 30s)")
        
        return True
        
    except Exception as e:
        print(f"  âŒ Erreur Performance: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Test principal"""
    print("ğŸ§ª TESTS DES AMÃ‰LIORATIONS SOPHIA")
    print("=" * 60)
    
    tests = [
        ("Concept Bridge", test_concept_bridge),
        ("Constraint Manager", test_constraint_manager),
        ("SophIA Enhanced", test_enhanced_sophia),
        ("Performance", test_performance)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nğŸš€ Test: {test_name}")
        print("-" * 40)
        
        try:
            success = test_func()
            results.append((test_name, success))
            
        except Exception as e:
            print(f"ğŸ’¥ {test_name}: ERREUR FATALE - {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # RÃ©sumÃ© final
    print("\n" + "=" * 60)
    print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("-" * 30)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… RÃ‰USSI" if success else "âŒ Ã‰CHOUÃ‰"
        print(f"{test_name:<20} {status}")
    
    print(f"\nğŸ¯ SCORE FINAL: {passed}/{total} tests rÃ©ussis ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nğŸ‰ TOUTES LES AMÃ‰LIORATIONS FONCTIONNENT PARFAITEMENT !")
        print("\nğŸš€ Prochaines Ã©tapes:")
        print("1. Lance: python simple_interface.py")
        print("2. Lance: python launch_web.py") 
        print("3. Teste avec des questions complexes!")
        print("4. Observe les amÃ©liorations (synonymes, validation, etc.)")
    elif passed > 0:
        print(f"\nâœ… {passed} amÃ©liorations fonctionnent, {total-passed} ont des problÃ¨mes.")
        print("VÃ©rifiez les erreurs ci-dessus pour les corriger.")
    else:
        print("\nâŒ Aucune amÃ©lioration ne fonctionne.")
        print("VÃ©rifiez que les fichiers sont bien crÃ©Ã©s et les imports corrects.")
    
    return passed == total

if __name__ == '__main__':
    success = main()
    print(f"\n{'ğŸ‰ SUCCÃˆS' if success else 'âš ï¸ Ã‰CHEC'} - Test terminÃ©")