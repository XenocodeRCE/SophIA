# Configuration SophIA
sophia:
  name: "SophIA"
  version: "0.1.0"
  
# Ontologie
ontology:
  max_concepts: 50000
  auto_expand: true
  philosophy_focus: true
  
# LLM Configuration
llm:
  model_name: "meta-llama/Llama-3-8b-instruct"
  quantization: "4bit"
  max_length: 2048
  temperature: 0.7
  device: "auto"
  
# Training
training:
  auto_save_frequency: 5
  max_epochs: 100
  consistency_weight: 0.3
  learning_rate: 0.001
  
# Storage
storage:
  models_dir: "./models"
  checkpoints_dir: "./models/checkpoints"
  logs_dir: "./logs"
  
# Autonomous Learning
autonomous:
  enabled: false
  clipboard_monitor: true
  screen_monitor: false
  learning_threshold: 0.5
  
# Performance
performance:
  cache_size: 10000
  parallel_processing: true
  memory_limit_gb: 8